{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea706a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 14:40:50,852 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 14:40:56,401 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 14:40:57,967 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.079: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:03<00:00,  4.00s/it]                                                                                          \n",
      "rtf_avg: 0.017: 100%|\u001b[34m██████████\u001b[0m| 5/5 [00:02<00:00,  1.76it/s]\n",
      "rtf_avg: 0.031: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.87s/it]\n",
      "rtf_avg: 0.033: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.99s/it]\n",
      "rtf_avg: 0.033: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.99s/it]\n",
      "rtf_avg: 0.032: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.96s/it]\n",
      "rtf_avg: 0.030: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.80s/it]\n",
      "rtf_avg: 0.033: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  2.00s/it]\n",
      "rtf_avg: -1.649: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.66s/it]\n",
      "rtf_avg: 0.031, time_speech:  529.810, time_escape: 16.199: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:16<00:00, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW TYPE ===\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from funasr import AutoModel\n",
    "\n",
    "# 使用项目测试音频\n",
    "audio_path = r\"C:\\Users\\ke\\Documents\\projects\\python_projects\\HearSight\\backend\\tests\\datas\\大语言模型进化论：从“听懂指令”到“学会思考”，AI如何与人类对齐？.m4a\"\n",
    "assert os.path.exists(audio_path), f\"文件不存在: {audio_path}\"\n",
    "\n",
    "# 最小模型加载（与项目一致）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModel(\n",
    "    model=\"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\",\n",
    "    model_revision=\"v2.0.4\",\n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_model_revision=\"v2.0.4\",\n",
    "    punc_model=\"ct-punc-c\",\n",
    "    punc_model_revision=\"v2.0.4\",\n",
    "    device=device,\n",
    "    disable_update=True,\n",
    ")\n",
    "\n",
    "# 推理：返回原始结构\n",
    "res = model.generate(input=audio_path, cache={}, batch_size_s=300)\n",
    "\n",
    "print(\"=== RAW TYPE ===\")\n",
    "print(type(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d6bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ITEM KEYS ===\n",
      "['key', 'text', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 安全展开首项\n",
    "item = res[0] if isinstance(res, list) and res else {}\n",
    "print(\"\\n=== ITEM KEYS ===\")\n",
    "print(list(item.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8563e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASIC FIELDS ===\n",
      "key: 大语言模型进化论：从“听懂指令”到“学会思考”，AI如何与人类对齐？\n",
      "text type: <class 'str'>\n",
      "text sample: 想象一下啊，人工智能现在哎好像越来越能听懂我们说话了。有时候甚至你给他举个例子，他就能学会一个新任务，让背后到底是怎么回事呢？今天我们就来聊聊你分享的这些资料，看看这些大语言模型啊是怎么一步步进化。从原来那种需要好多定制训练，现在能更灵活的...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 基本字段\n",
    "print(\"\\n=== BASIC FIELDS ===\")\n",
    "print(\"key:\", item.get(\"key\"))\n",
    "print(\"text type:\", type(item.get(\"text\")))\n",
    "if isinstance(item.get(\"text\"), str):\n",
    "    print(\"text sample:\", item[\"text\"][:120] + (\"...\" if len(item[\"text\"]) > 120 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ec01bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TIMESTAMP FIELD ===\n",
      "timestamp type: <class 'list'>\n",
      "timestamp length: 2264\n",
      "timestamp[0] (ms): [350, 590]\n",
      "timestamp[0] (s): [0.35, 0.59]\n",
      "\n",
      "first_5_timestamp_intervals_s:\n",
      "[0.35, 0.59]\n",
      "[0.65, 0.89]\n",
      "[0.91, 1.01]\n",
      "[1.01, 1.25]\n",
      "[1.25, 1.45]\n",
      "\n",
      "Saved results/paraformer_raw_probe.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 重点：timestamp 为二维数组 [start_ms, end_ms]\n",
    "ts = item.get(\"timestamp\")\n",
    "print(\"\\n=== TIMESTAMP FIELD ===\")\n",
    "print(\"timestamp type:\", type(ts))\n",
    "if isinstance(ts, list):\n",
    "    print(\"timestamp length:\", len(ts))\n",
    "    if ts and isinstance(ts[0], (list, tuple)) and len(ts[0]) == 2:\n",
    "        print(\"timestamp[0] (ms):\", ts[0])\n",
    "\n",
    "        # 假设单位是毫秒(ms)，转换为秒(float，保留3位)\n",
    "        def ms_to_s(ms: int) -> float:\n",
    "            return round(ms / 1000.0, 3)\n",
    "\n",
    "        ts_s = [[ms_to_s(p[0]), ms_to_s(p[1])] for p in ts]\n",
    "        print(\"timestamp[0] (s):\", ts_s[0])\n",
    "\n",
    "        # 打印前5个区间样例\n",
    "        print(\"\\nfirst_5_timestamp_intervals_s:\")\n",
    "        for pair in ts_s[:5]:\n",
    "            print(pair)\n",
    "\n",
    "        # 可选：导出一个简化结构，便于你进一步处理\n",
    "        out = {\n",
    "            \"key\": item.get(\"key\"),\n",
    "            \"text\": item.get(\"text\"),\n",
    "            \"timestamp_ms\": ts,         # 原始毫秒\n",
    "            \"timestamp_s\": ts_s[:50],   # 只导出前50个，避免过大\n",
    "        }\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        with open(\"results/paraformer_raw_probe.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "        print('\\nSaved results/paraformer_raw_probe.json')\n",
    "    else:\n",
    "        print(\"timestamp 不是二维 [start_ms, end_ms] 数组，请再贴样例我再适配。\")\n",
    "else:\n",
    "    print(\"timestamp 缺失或类型非 list。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 16:11:49,224 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 16:11:54,947 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ke\\.cache\\modelscope\\hub\\models\\iic\\punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 16:11:57,465 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.072: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:03<00:00,  3.61s/it]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 5/5 [00:02<00:00,  2.04it/s]\n",
      "rtf_avg: 0.027: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.64s/it]\n",
      "rtf_avg: 0.027: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.65s/it]\n",
      "rtf_avg: 0.027: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.61s/it]\n",
      "rtf_avg: 0.027: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.64s/it]\n",
      "rtf_avg: 0.027: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.61s/it]\n",
      "rtf_avg: 0.029: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.74s/it]\n",
      "rtf_avg: -1.381: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.39s/it]\n",
      "rtf_avg: 0.026, time_speech:  529.810, time_escape: 13.836: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:14<00:00, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences: 70\n",
      "0 {'sentence': '想象一下啊，人工智能现在哎好像越来越能听懂我们说话了。', 'start_s': 0.35, 'end_s': 5.75}\n",
      "1 {'sentence': '有时候甚至你给他举个例子，他就能学会一个新任务，让背后到底是怎么回事呢？', 'start_s': 5.75, 'end_s': 13.084}\n",
      "2 {'sentence': '今天我们就来聊聊你分享的这些资料，看看这些大语言模型啊是怎么一步步进化。', 'start_s': 13.084, 'end_s': 20.357}\n",
      "3 {'sentence': '从原来那种需要好多定制训练，现在能更灵活的学习和推理的。', 'start_s': 20.357, 'end_s': 25.746}\n",
      "4 {'sentence': '这里面呢有几个关键的技术点，让AI变得越来越聪明了。', 'start_s': 25.746, 'end_s': 30.738}\n",
      "Saved to results/paraformer_sentence_times.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from funasr import AutoModel\n",
    "\n",
    "# 1) 加载并推理（与现有配置一致，音频路径用你的测试文件）\n",
    "AUDIO_PATH = r\"C:\\Users\\ke\\Documents\\projects\\python_projects\\HearSight\\backend\\tests\\datas\\大语言模型进化论：从“听懂指令”到“学会思考”，AI如何与人类对齐？.m4a\"\n",
    "assert os.path.exists(AUDIO_PATH), f\"文件不存在: {AUDIO_PATH}\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModel(\n",
    "    model=\"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\",\n",
    "    model_revision=\"v2.0.4\",\n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_model_revision=\"v2.0.4\",\n",
    "    punc_model=\"ct-punc-c\",\n",
    "    punc_model_revision=\"v2.0.4\",\n",
    "    device=DEVICE,\n",
    "    disable_update=True,\n",
    ")\n",
    "\n",
    "res = model.generate(input=AUDIO_PATH, cache={}, batch_size_s=300)\n",
    "item: Dict[str, Any] = res[0] if isinstance(res, list) and res else {}\n",
    "text: str = item.get(\"text\", \"\") or \"\"\n",
    "timestamps: List[List[int]] = item.get(\"timestamp\", []) or []\n",
    "\n",
    "# 2) 快速近似：文本分句 + 映射到有声时间累计进度\n",
    "\n",
    "def split_cn_sentences(text: str) -> List[Tuple[int, int, str]]:\n",
    "    \"\"\"\n",
    "    简单中文分句，返回 [(start_idx, end_idx, sentence)]，end_idx 不含。保留句末标点。\n",
    "    标点集：。！？；（可按需扩展）\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    spans = []\n",
    "    start = 0\n",
    "    for m in re.finditer(r'[。！？；]', text):\n",
    "        end = m.end()\n",
    "        sent = text[start:end]\n",
    "        if sent.strip():\n",
    "            spans.append((start, end, sent))\n",
    "        start = end\n",
    "    if start < len(text):  # 末尾残句\n",
    "        sent = text[start:]\n",
    "        if sent.strip():\n",
    "            spans.append((start, len(text), sent))\n",
    "    return spans\n",
    "\n",
    "def map_charpos_to_time_ms(pos: int, text_len: int, seg_ms: List[Tuple[int, int]]) -> int:\n",
    "    \"\"\"\n",
    "    将字符位置 pos (0..text_len) 映射到时间(ms)。\n",
    "    思路：仅按“有声累计时长”线性分配（忽略静音间隔）。\n",
    "    \"\"\"\n",
    "    if text_len <= 0 or not seg_ms:\n",
    "        return 0\n",
    "    total_voiced = sum(e - s for s, e in seg_ms)\n",
    "    if total_voiced <= 0:\n",
    "        return seg_ms[0][0]\n",
    "\n",
    "    target = total_voiced * (pos / text_len)  # 目标有声累计时长\n",
    "    acc = 0.0\n",
    "    for s, e in seg_ms:\n",
    "        dur = e - s\n",
    "        if dur <= 0:\n",
    "            continue\n",
    "        if acc + dur >= target:\n",
    "            inside = target - acc\n",
    "            return int(round(s + inside))\n",
    "        acc += dur\n",
    "    return seg_ms[-1][1]\n",
    "\n",
    "def sentences_with_times(text: str, timestamps_ms: List[List[int]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    输入：整段 text 与 VAD 窗口 timestamps_ms -> 近似句子时间范围（秒）\n",
    "    输出：[{sentence, start_s, end_s}]\n",
    "    \"\"\"\n",
    "    seg_ms = [(int(s), int(e)) for s, e in timestamps_ms if isinstance(s, (int, float)) and isinstance(e, (int, float))]\n",
    "    seg_ms = [(s, e) for s, e in seg_ms if e > s]\n",
    "    if not text or not seg_ms:\n",
    "        return []\n",
    "\n",
    "    sents = split_cn_sentences(text)\n",
    "    n = len(text)\n",
    "    out = []\n",
    "    for s_idx, e_idx, sent in sents:\n",
    "        st_ms = map_charpos_to_time_ms(s_idx, n, seg_ms)\n",
    "        ed_ms = map_charpos_to_time_ms(e_idx, n, seg_ms)\n",
    "        if ed_ms < st_ms:\n",
    "            ed_ms = st_ms\n",
    "        out.append({\n",
    "            \"sentence\": sent,\n",
    "            \"start_s\": round(st_ms / 1000.0, 3),\n",
    "            \"end_s\": round(ed_ms / 1000.0, 3),\n",
    "        })\n",
    "    return out\n",
    "\n",
    "# 3) 执行近似并输出结果\n",
    "sentence_spans = sentences_with_times(text, timestamps)\n",
    "\n",
    "print(f\"total sentences: {len(sentence_spans)}\")\n",
    "for i, sp in enumerate(sentence_spans[:5]):  # 只看前5条样例\n",
    "    print(i, sp)\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/paraformer_sentence_times.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sentence_spans, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved to results/paraformer_sentence_times.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ffb07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
