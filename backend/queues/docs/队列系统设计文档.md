# 队列系统设计文档

## 架构概览

使用Celery+Redis实现异步任务队列，替代原有的数据库轮询机制。Worker独立运行，通过Redis消息broker与FastAPI后端解耦通信。

```
FastAPI (backend) 
    ↓ 提交任务
Redis (broker)
    ↓ 分配
Celery Worker
    ↓ 执行结果
PostgreSQL (数据库)
```

## 核心组件

### 1. Worker启动器 (worker_launcher.py)

**职责**：初始化并启动Celery Worker进程

**关键流程**：
- 自动检测运行环境（Docker /app 或本地路径）
- 加载.env环境变量
- 读取worker配置参数（并发数、日志级别）
- 通过create_celery_app()创建Celery应用实例
- 启动worker进程

**配置参数**（来自环境变量）：
- `CELERY_WORKER_CONCURRENCY`：并发worker数（默认4）
- `CELERY_LOG_LEVEL`：日志级别（默认info）
- `CELERY_BROKER_URL`：Redis Broker地址
- `CELERY_RESULT_BACKEND`：Redis结果存储地址

**超时设置**：
- 硬超时：3600秒（任务必须在此时间内完成）
- 软超时：3300秒（触发SoftTimeLimitExceeded异常）

### 2. 任务定义 (tasks.py)

**核心任务**：`process_job_task(job_id, url, static_dir, db_url)`

**执行分三阶段**：

#### 阶段A：下载 (Download)
- 检测输入类型：
  - `upload://` 开头：已上传文件，跳过下载，直接进入ASR
  - 其他URL：从网络下载视频/音频
- 下载时实时回调进度更新到数据库
- 记录media_path用于后续恢复

#### 阶段B：语音识别 (ASR)
- 检测媒体类型（音频/视频）
- 调用asr_process()执行语音识别
- 保存转录结果到数据库（transcript）
- 中间进度更新（0% → 50% → 100%）

#### 阶段C：完成 (Completion)
- 标记任务为success或failed
- 更新job表最终状态
- 触发完成回调

**错误处理**：
- 自动重试：最多3次，指数退避
- 任何阶段失败记录错误信息到数据库
- 支持断点续传（检查res中是否已完成某阶段）

**进度反馈**：
- 通过set_task_progress()实时推送到前端
- 包含：状态、阶段、进度百分比、文件名、提示信息
- 用于WebSocket或轮询更新UI

## 数据流

```
前端 POST /api/jobs/create
    ↓
FastAPI handler
    ↓ 调用 process_job_task.delay()
Redis Broker 入队
    ↓
Worker 取出任务
    ↓ 执行三阶段逻辑
PostgreSQL 数据库（实时更新status/result）
    ↓
set_task_progress() 回调
    ↓ 可选：WebSocket推送
前端实时显示进度
```

## 工作流序列图

```
前端          后端          数据库         Worker
 │            │               │             │
 ├─POST job──→│               │             │
 │            ├─保存job状态─→ │             │
 │            ├─提交Task────────────────→  │
 │            │               │        执行 │
 │            │            状态更新  ←─ ────┤
 │◄─(轮询)────┤◄─查询进度────│             │
 │  status    │            返回            │
 │            │               │             │
 │            │            完成  ←─ ────────┤
 │◄─结果──────┤◄─查询结果────│             │
```

## 相关文件关系

```
backend/config.py
    ├─ Settings：全局配置
    └─ create_celery_app()：创建Celery应用（broker/backend配置）

backend/queues/
    ├─ tasks.py：process_job_task定义（业务逻辑）
    ├─ worker_launcher.py：Worker启动脚本
    ├─ __main__.py：模块入口（支持 python -m backend.queues）
    └─ docs/：文档

backend/routers/
    ├─ download_router.py：提交任务到Celery
    └─ job_router.py：查询任务状态和Celery结果

backend/db/
    ├─ job_store.py：job表操作（CRUD）
    └─ transcript_crud.py：transcript表操作

前端/后端交互：
    ├─ POST /api/jobs/create：创建job + 提交Task
    ├─ GET /api/jobs?status=pending：轮询未完成任务
    └─ GET /api/celery/tasks/{task_id}：查询Celery任务状态
```

## 关键设计决策

### 为何使用Celery而非数据库轮询？
- **性能**：事件驱动而非1秒轮询，减少数据库压力
- **可扩展**：Worker数量可独立扩展
- **监控**：Celery提供任务监控和统计

### 为何保留media_path在result中？
- 支持断点续传，若网络中断可重试时直接使用本地文件
- 避免重复下载

### 为何超时设置较长（3600秒）？
- 大文件下载和ASR处理耗时
- 软超时触发异常后有5分钟响应机会
- 硬超时前强制终止防止僵尸进程

## 环境配置示例

```bash
# .env 文件
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1
CELERY_WORKER_CONCURRENCY=4
CELERY_LOG_LEVEL=info
```

## 启动方式

**本地开发**：
```bash
python -m backend.queues
# 或
python backend/queues/worker_launcher.py
```

**Docker容器**：
```yaml
celery-worker:
  command: python -m backend.queues.worker_launcher
  working_dir: /app
```

## 监控与调试

**查看任务状态**：
- `celery -A backend.queues.tasks inspect active`
- `celery -A backend.queues.tasks inspect stats`

**实时日志**：
- Worker日志输出包含任务执行情况
- 支持通过CELERY_LOG_LEVEL环境变量调整日志级别
