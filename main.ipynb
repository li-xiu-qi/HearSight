{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4df3fa",
   "metadata": {},
   "source": [
    "# 文档导航\n",
    "\n",
    "本教程notebook涵盖HearSight项目的完整指南，以下是主要章节索引：\n",
    "\n",
    "## 目录\n",
    "\n",
    "1. [项目介绍](#HearSight-项目教程)\n",
    "   - 项目概述\n",
    "   - 技术架构\n",
    "   - 核心能力\n",
    "   - 核心技术策略\n",
    "   - 效果展示\n",
    "\n",
    "2. [快速开始](#快速开始)\n",
    "   - 环境配置\n",
    "   - 容器化部署\n",
    "   - 本地开发部署\n",
    "\n",
    "3. [ASR Backend](#ASR-Backend-快速开始)\n",
    "   - 云端模式启动\n",
    "   - 本地模式启动\n",
    "   - Docker启动\n",
    "   - 基本使用\n",
    "   - 配置指南\n",
    "\n",
    "4. [主后端服务](#HearSight-主后端快速开始)\n",
    "   - 环境配置\n",
    "   - 容器化部署\n",
    "   - 本地部署\n",
    "   - 验证服务\n",
    "\n",
    "5. [前端应用](#HearSight-前端快速开始)\n",
    "   - 环境准备\n",
    "   - 安装依赖\n",
    "   - 容器化部署\n",
    "   - 本地开发\n",
    "\n",
    "6. [功能详解](#功能详解)\n",
    "   - 多源媒体导入\n",
    "   - 精准语音识别\n",
    "   - 智能内容分析\n",
    "   - 多语言翻译\n",
    "   - 深度问答\n",
    "   - 图文融合\n",
    "\n",
    "7. [适用场景](#适用场景)\n",
    "\n",
    "8. [项目结构](#项目结构详细说明)\n",
    "\n",
    "9. [Radxa设备部署](#Radxa设备大语言模型部署指南)\n",
    "   - Llama.cpp\n",
    "   - Ollama\n",
    "\n",
    "10. [ARM设备Docker构建](#ARM设备Docker构建指南)\n",
    "    - 构建流程\n",
    "    - 环境配置\n",
    "    - 直接构建\n",
    "    - 交叉构建\n",
    "\n",
    "11. [总结](#总结)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ee206",
   "metadata": {},
   "source": [
    "# HearSight 项目教程\n",
    "\n",
    "本notebook基于HearSight项目的README.md和docs中的快速开始指南，提供详细的教程。\n",
    "\n",
    "![HearSight logo](https://oss-liuchengtu.hudunsoft.com/userimg/33/3374fce0ebc0d82f093c6c7361b84fcc.png)\n",
    "\n",
    "HearSight 是一个音视频内容智能分析工具。通过集成先进的语音识别、自然语言处理和大语言模型技术，HearSight 能够自动将视频和音频转化为结构化的文本内容，并在此基础上进行多维度的智能分析和交互。\n",
    "\n",
    "[B站视频介绍](https://www.bilibili.com/video/BV1D5UgBYEtC/?vd_source=325d9b8b91626b0afd2ef63a99caf970)\n",
    "\n",
    "<div style=\"text-align: center; margin: auto;\">\n",
    "    <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=115602047899223&bvid=BV1D5UgBYEtC&cid=34218837346&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe>\n",
    "</div>\n",
    "\n",
    "项目地址：<https://github.com/li-xiu-qi/HearSight>\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "HearSight 采用现代化的微服务架构设计。后端基于 FastAPI 构建高性能 RESTful API，通过 PostgreSQL 实现数据的持久化和查询优化，通过 Celery 构建任务队列处理异步任务；前端采用 React 18 + TypeScript + Tailwind CSS 提供交互流畅的用户界面。整体支持 Docker 容器化部署，开箱即用。\n",
    "\n",
    "![架构图](https://oss-liuchengtu.hudunsoft.com/userimg/b5/b54f2ca20885a98aa90ec0557b8354e1.png)\n",
    "\n",
    "![微服务技术架构概览](https://oss-liuchengtu.hudunsoft.com/userimg/c8/c8ae4f200c345d26e5ec0d4fe3bc169b.png)\n",
    "\n",
    "## 核心能力\n",
    "\n",
    "- 📹 集成式媒体导入：直接从哔哩哔哩获取内容，同时支持本地上传视频和音频文件，支持 MP4、AVI、MOV、MKV、MP3、WAV、M4A、AAC 等多种格式\n",
    "- 🎯 精准语音转写：采用业界领先的 ASR 技术，支持热词识别和实时精确时间戳，自动分句并生成可交互式的文本档案\n",
    "- 🧠 智能内容分析：基于大语言模型生成段落级和全文级的结构化摘要，支持持久化保存和迭代优化\n",
    "- 💬 对话式内容理解：支持基于原文的深度问答交互，准确把握关键信息和核心观点\n",
    "- 🖼️ 多模态信息展示：在问答和总结中融入视频关键帧，实现图文融合的高效表达（仅适用于视频内容）\n",
    "- 🌐 多语言内容转换：支持自动翻译为多种语言，翻译结果完整保存，便于国际化场景使用\n",
    "\n",
    "## 效果展示\n",
    "\n",
    "视频播放页展示：\n",
    "![视频播放页展示](https://oss-liuchengtu.hudunsoft.com/userimg/27/27e3d807bc8e6a3abf5739eeb5effb27.png)\n",
    "\n",
    "打开一个视频：\n",
    "![打开一个视频](https://oss-liuchengtu.hudunsoft.com/userimg/8d/8daf5b438a9de50fd4425ee1518536a9.png)\n",
    "\n",
    "打开视频后的文稿效果展示：\n",
    "![打开视频后的文稿效果展示](https://oss-liuchengtu.hudunsoft.com/userimg/f5/f548ca996e1b001e371df9bca74fc60a.png)\n",
    "\n",
    "视频总结的展示：\n",
    "![视频总结的展示](https://oss-liuchengtu.hudunsoft.com/userimg/de/defdd1d7dd03e7b34f34232895455dd9.png)\n",
    "![视频总结的放大图片展示](https://oss-liuchengtu.hudunsoft.com/userimg/0f/0f4df03f82e2250bc3c6f77d87514f8c.png)\n",
    "\n",
    "与视频之间的智能对话：\n",
    "![与视频之间的智能对话](https://oss-liuchengtu.hudunsoft.com/userimg/73/73c98a266a46f1b4524772227c89f23a.png)\n",
    "\n",
    "![与视频之间的智能对话](https://oss-liuchengtu.hudunsoft.com/userimg/4b/4bd189d43bc033aa1b3e3abc14f9bac6.png)\n",
    "\n",
    "![图文模式对话图片放大展示](https://oss-liuchengtu.hudunsoft.com/userimg/45/45b084440a50e098229d8c827ab5f01f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628a74f",
   "metadata": {},
   "source": [
    "## 核心技术策略\n",
    "\n",
    "#### Embedding 文件名增强策略\n",
    "\n",
    "在知识库检索环节，我们实现了 embedding 文件名增强技术。通过在生成文本向量时，将文件名信息与内容文本相结合，形成更丰富的上下文嵌入。具体实现是在 chunk_text 前添加文件名描述，如 \"文件名：[filename]\\n内容：[text]\"，从而提升基于文件名提问的检索准确性。该策略有效解决了传统 embedding 仅基于内容而忽略文件名导致的检索不准问题，显著改善了用户查询体验，因为用户基于文件标题提问，很容易错漏相关文件，而给文件名一起进行embedding，会使得整个的效率，召回率平均能提升30%以上。\n",
    "\n",
    "![文件名增强embedding](https://oss-liuchengtu.hudunsoft.com/userimg/04/04e4675db680c35a70dd6ead54b5a6ce.png)\n",
    "\n",
    "#### ReAct 记忆管理策略\n",
    "\n",
    "在对话问答系统中，我们采用了先进的 ReAct 记忆管理机制，以应对大语言模型的上下文长度限制。通过智能的记忆压缩和上下文重组，当对话积累的消息超过阈值时，系统自动生成对话摘要，将关键信息压缩存储，同时保留完整的消息历史用于精确重组。这种增量总结策略确保了多轮对话的连贯性，避免了信息丢失，同时控制了上下文长度，提升了问答系统的稳定性和效率。记忆管理分为对话记忆和任务执行记忆两层，前者维持用户与助手的对话连贯性，后者管理单次任务的推理过程，确保了系统的可扩展性和性能优化。\n",
    "\n",
    "![ReAct双层记忆管理机制](https://oss-liuchengtu.hudunsoft.com/userimg/ff/fff9b992a690c7030ddf99bee7f57174.png)\n",
    "\n",
    "![ReAct后端问答设计](https://oss-liuchengtu.hudunsoft.com/userimg/a3/a327b36d0ddb4fcaa99a27a4f4cfff42.png)\n",
    "\n",
    "#### 检索内容重组策略\n",
    "\n",
    "在多视频问答场景中，我们设计了层次化的检索内容重组结构，以确保不同视频和内容块有清晰的分界线。该结构采用嵌套标签系统：[视频开始/结束] 包围整个视频内容，[块开始/结束] 分隔连续的内容片段，每个句子附带精确的时间戳 [filename start-end]。这种设计避免了多视频内容混淆的问题，使大语言模型能够准确识别和引用特定视频段落，提升问答的精确性和可追溯性，同时保持提示词的结构化和可读性。\n",
    "\n",
    "![检索内容重组策略](https://oss-liuchengtu.hudunsoft.com/userimg/9c/9c5fa9824b2395d8563890d05a7e73ac.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf3c7f",
   "metadata": {},
   "source": [
    "## 快速开始\n",
    "\n",
    "### 获取源代码\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/li-xiu-qi/HearSight\n",
    "cd HearSight\n",
    "```\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "在项目根目录创建 `.env` 文件，按需配置以下参数：\n",
    "\n",
    "```bash\n",
    "# PostgreSQL 数据库（必需）\n",
    "POSTGRES_USER=hearsight\n",
    "POSTGRES_PASSWORD=hearsight_pass\n",
    "POSTGRES_DB=hearsight\n",
    "POSTGRES_PORT=5432\n",
    "\n",
    "# 服务端口（可选）\n",
    "BACKEND_PORT=9999\n",
    "FRONTEND_PORT=10000\n",
    "ASR_BACKEND_PORT=8003\n",
    "REDIS_PORT=6379\n",
    "\n",
    "# 大语言模型（必需，推荐使用百度AI Studio）\n",
    "# 百度AI Studio配置（推荐）\n",
    "AI_STUDIO_API_KEY=your_api_key_here\n",
    "OPENAI_BASE_URL=https://aistudio.baidu.com/llm/lmapi/v3\n",
    "OPENAI_CHAT_MODEL=ernie-4.5-300B-A47B\n",
    "\n",
    "# 或者使用硅基流动平台\n",
    "# OPENAI_API_KEY=your_siliconflow_api_key\n",
    "# OPENAI_BASE_URL=https://api.siliconflow.cn/v1\n",
    "# OPENAI_CHAT_MODEL=baidu/ERNIE-4.5-300B-A47B\n",
    "\n",
    "# 对话上下文窗口（可选）\n",
    "CHAT_MAX_WINDOWS=1000000\n",
    "\n",
    "# 哔哩哔哩登录凭证（可选，用于获取会员视频）\n",
    "BILIBILI_SESSDATA=\n",
    "```\n",
    "\n",
    "在 `backend/` 目录下创建 `.env` 文件：\n",
    "\n",
    "```bash\n",
    "# 复制模板\n",
    "cp .env.example backend/.env\n",
    "# 编辑配置\n",
    "```\n",
    "\n",
    "在 `ASRBackend/` 目录下创建 `.env` 文件：\n",
    "\n",
    "```bash\n",
    "# ASR 相关配置\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=your_dashscope_api_key\n",
    "SUPABASE_URL=https://your-project.supabase.co\n",
    "SUPABASE_KEY=your-anon-key\n",
    "SUPABASE_BUCKET_NAME=test-public\n",
    "SUPABASE_FOLDER_NAME=asr\n",
    "SUPABASE_ADMIN_EMAIL=your-email@example.com\n",
    "SUPABASE_ADMIN_PASSWORD=your-password\n",
    "```\n",
    "\n",
    "快速提示：项目推荐使用百度AI Studio的OpenAI兼容API作为LLM服务，可使用ernie-4.5-300B-A47B模型。配置AI_STUDIO_API_KEY（对应OpenAI SDK的api_key字段）和base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\"（对应OpenAI SDK的base_url字段）即可。更具体的内容可以参考：https://ai.baidu.com/ai-doc/AISTUDIO/rm344erns。Embedding服务默认使用硅基流动的OpenAI兼容API，平台地址：https://siliconflow.cn，免费额度申请：https://cloud.siliconflow.cn/i/FcjKykMn。DASHSCOPE_API_KEY 可从阿里云百炼获取。\n",
    "\n",
    "### 容器化部署（推荐）\n",
    "\n",
    "一行命令启动完整服务栈：\n",
    "\n",
    "```bash\n",
    "docker-compose -f docker-compose.cloud.yml up -d --build\n",
    "```\n",
    "\n",
    "部署完成后，访问 <http://localhost:10000> 即可进入应用。\n",
    "\n",
    "如果仅需使用容器运行 PostgreSQL 数据库，而将后端和前端分别在本地启动，请参考下方本地部署方案。\n",
    "\n",
    "### ARM设备部署\n",
    "\n",
    "如果您在ARM架构设备（如ARM64处理器）上部署HearSight，推荐直接在ARM设备上构建镜像，无需交叉编译（包含交叉编辑教程）。详细步骤请参考 [ARM设备Docker构建指南](docs/ARM设备Docker构建指南.md)。\n",
    "\n",
    "### 本地开发部署\n",
    "\n",
    "#### 前置要求\n",
    "\n",
    "需要 PostgreSQL 数据库运行。可通过 Docker 启动也可本地安装。\n",
    "\n",
    "#### 后端服务启动\n",
    "\n",
    "1. 安装依赖\n",
    "\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. 安装 PyTorch\n",
    "\n",
    "   访问 <https://pytorch.org/get-started/locally/> 选择对应硬件版本\n",
    "\n",
    "3. 启动服务\n",
    "\n",
    "   ```bash\n",
    "   python main.py\n",
    "   ```\n",
    "\n",
    "   后端运行在 `http://localhost:9999`\n",
    "\n",
    "#### 前端应用启动\n",
    "\n",
    "1. 安装依赖\n",
    "\n",
    "   ```bash\n",
    "   cd frontend\n",
    "   npm install\n",
    "   ```\n",
    "\n",
    "2. 启动开发服务器\n",
    "\n",
    "   ```bash\n",
    "   npm run dev\n",
    "   ```\n",
    "\n",
    "前端在 `http://localhost:5173` 启动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47833a45",
   "metadata": {},
   "source": [
    "## ASR Backend 快速开始\n",
    "\n",
    "ASR Backend 是HearSight的语音识别服务组件。\n",
    "\n",
    "### 前置准备\n",
    "\n",
    "确保已完成环境配置。详见 [快速配置文档](ASRBackend/docs/快速配置.md) 文档。\n",
    "\n",
    "复制 `.env.example` 为 `.env` 并填入相关配置。\n",
    "\n",
    "根据运行模式安装对应依赖。\n",
    "\n",
    "### 启动流程概览\n",
    "\n",
    "[ASR Backend 启动流程概览图](docs/mermaid图汇集/ASR_Backend启动流程概览图.md)\n",
    "\n",
    "### 云端模式启动（推荐）\n",
    "\n",
    "云端模式轻量级，适合大多数场景。\n",
    "\n",
    "#### 步骤 1：获取 API Key\n",
    "\n",
    "访问阿里云 DashScope 控制台 https://dashscope.console.aliyun.com/ 获取 API Key。\n",
    "\n",
    "若未有阿里云账户，需先注册。\n",
    "\n",
    "#### 步骤 2：配置环境\n",
    "\n",
    "编辑 `.env` 文件，填入 DashScope API Key。\n",
    "\n",
    "```env\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=sk-xxx\n",
    "```\n",
    "\n",
    "#### 步骤 3：安装依赖\n",
    "\n",
    "```bash\n",
    "pip install -r requirements-cloud.txt\n",
    "```\n",
    "\n",
    "#### 步骤 4：启动服务\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "服务将在 `http://localhost:8003` 启动。\n",
    "\n",
    "#### 步骤 5：验证服务\n",
    "\n",
    "打开浏览器访问 `http://localhost:8003/docs`，进入 Swagger 文档界面测试 API。\n",
    "\n",
    "或使用命令行测试。\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8003/health\n",
    "```\n",
    "\n",
    "健康检查返回 `{\"status\": \"healthy\", \"service\": \"ASR Backend\"}` 表示启动成功。\n",
    "\n",
    "### 本地模式启动\n",
    "\n",
    "本地模式完全离线运行，首次运行需下载模型文件，耗时较长。\n",
    "\n",
    "#### 步骤 1：配置环境\n",
    "\n",
    "编辑 `.env` 文件，设置运行模式为本地。\n",
    "\n",
    "```env\n",
    "ASR_MODE=local\n",
    "```\n",
    "\n",
    "#### 步骤 2：安装依赖\n",
    "\n",
    "```bash\n",
    "pip install -r requirements-local.txt\n",
    "```\n",
    "\n",
    "安装过程可能较长，取决于网络速度。\n",
    "\n",
    "#### 步骤 3：启动服务\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "首次启动会下载并初始化模型，可能需要 5-10 分钟，这属于正常现象。\n",
    "\n",
    "#### 步骤 4：验证服务\n",
    "\n",
    "等待模型加载完成后，服务启动成功。\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8003/health\n",
    "```\n",
    "\n",
    "### Docker 启动\n",
    "\n",
    "#### 云端模式（轻量级）\n",
    "\n",
    "```bash\n",
    "docker build -f Dockerfile.cloud -t hearsight-asr:cloud .\n",
    "\n",
    "docker run -p 8003:8003 \\\n",
    "  -e ASR_MODE=cloud \\\n",
    "  -e DASHSCOPE_API_KEY=sk-xxx \\\n",
    "  hearsight-asr:cloud\n",
    "```\n",
    "\n",
    "#### 本地模式（完整镜像）\n",
    "\n",
    "```bash\n",
    "docker build -f Dockerfile.local -t hearsight-asr:local .\n",
    "\n",
    "docker run -p 8003:8003 \\\n",
    "  -e ASR_MODE=local \\\n",
    "  hearsight-asr:local\n",
    "```\n",
    "\n",
    "#### Docker Compose\n",
    "\n",
    "直接使用 docker-compose 启动服务。\n",
    "\n",
    "```bash\n",
    "docker-compose up asr_backend\n",
    "```\n",
    "\n",
    "### 基本使用\n",
    "\n",
    "#### 查看 API 文档\n",
    "\n",
    "访问 http://localhost:8003/docs 进入交互式 API 文档。\n",
    "\n",
    "#### 获取服务信息\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8003/asr/info\n",
    "```\n",
    "\n",
    "返回当前运行模式、模型配置等信息。\n",
    "\n",
    "#### URL 转录\n",
    "\n",
    "使用公开的音频 URL 进行转录。\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://localhost:8003/asr/transcribe/url\" \\\n",
    "  -d \"url=https://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0010_8k.wav\"\n",
    "```\n",
    "\n",
    "#### 文件上传转录\n",
    "\n",
    "上传本地音频文件进行转录。\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://localhost:8003/asr/transcribe/upload\" \\\n",
    "  -F \"file=@audio.mp3\"\n",
    "```\n",
    "\n",
    "#### Python 调用\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# 文件上传\n",
    "with open(\"audio.mp3\", \"rb\") as f:\n",
    "    files = {\"file\": f}\n",
    "    response = requests.post(\"http://localhost:8003/asr/transcribe/upload\", files=files)\n",
    "    print(response.json())\n",
    "\n",
    "# URL 转录\n",
    "response = requests.post(\n",
    "    \"http://localhost:8003/asr/transcribe/url\",\n",
    "    data={\"url\": \"https://example.com/audio.wav\"}\n",
    ")\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "### 服务停止\n",
    "\n",
    "按 `Ctrl+C` 停止服务。\n",
    "\n",
    "若使用 Docker，执行 `docker stop` 命令停止容器。\n",
    "\n",
    "### 调试模式\n",
    "\n",
    "启用调试模式查看详细日志。\n",
    "\n",
    "编辑 `.env` 文件。\n",
    "\n",
    "```env\n",
    "DEBUG=true\n",
    "```\n",
    "\n",
    "或直接设置环境变量启动。\n",
    "\n",
    "```bash\n",
    "DEBUG=true python main.py\n",
    "```\n",
    "\n",
    "调试模式下会输出详细的日志信息，有助于定位问题。\n",
    "\n",
    "### 常见问题\n",
    "\n",
    "#### 服务无法启动\n",
    "\n",
    "检查端口 8003 是否被占用。修改 `PORT` 环境变量使用其他端口。\n",
    "\n",
    "检查依赖是否完整安装，可尝试重新安装。\n",
    "\n",
    "```bash\n",
    "pip install --upgrade -r requirements-cloud.txt\n",
    "```\n",
    "\n",
    "#### 云端模式无法连接\n",
    "\n",
    "确认 DashScope API Key 正确有效。\n",
    "\n",
    "检查网络连接是否正常。\n",
    "\n",
    "#### 本地模式运行缓慢\n",
    "\n",
    "本地模式首次运行需加载大型模型文件，属于正常现象。\n",
    "\n",
    "可将模型下载到固定位置加速后续启动。\n",
    "\n",
    "若运行速度仍然很慢，考虑使用云端模式。\n",
    "\n",
    "#### 文件上传失败\n",
    "\n",
    "确认已配置 Supabase 相关环境变量。\n",
    "\n",
    "检查 Supabase 配置是否有效。\n",
    "\n",
    "确认音频文件格式支持且文件大小在限制内。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e3267",
   "metadata": {},
   "source": [
    "### ASR Backend 快速配置\n",
    "\n",
    "#### 环境要求\n",
    "\n",
    "Python 版本 3.8 或以上。\n",
    "\n",
    "系统依赖根据运行模式不同而异。本地模式需要 CUDA 工具链支持 GPU 加速，云端模式无此要求。\n",
    "\n",
    "网络连接仅云端模式需要。\n",
    "\n",
    "#### 依赖安装\n",
    "\n",
    "##### 通用依赖\n",
    "\n",
    "所有模式都需要的基础依赖。\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "##### 云端模式依赖\n",
    "\n",
    "云端模式只需要轻量级依赖。\n",
    "\n",
    "```bash\n",
    "pip install -r requirements-cloud.txt\n",
    "```\n",
    "\n",
    "##### 本地模式依赖\n",
    "\n",
    "本地模式需要 PyTorch 和相关计算库，可能较大且耗时较长。\n",
    "\n",
    "```bash\n",
    "pip install -r requirements-local.txt\n",
    "```\n",
    "\n",
    "或通过国内镜像加速安装。\n",
    "\n",
    "```bash\n",
    "pip install -r requirements-local.txt -i https://pypi.tsinghua.edu.cn/simple\n",
    "```\n",
    "\n",
    "#### 环境变量配置\n",
    "\n",
    "复制示例文件作为配置文件。\n",
    "\n",
    "```bash\n",
    "cp .env.example .env\n",
    "```\n",
    "\n",
    "根据需要修改 `.env` 文件中的配置项。\n",
    "\n",
    "##### 基本配置\n",
    "\n",
    "| 变量 | 说明 | 默认值 |\n",
    "|------|------|--------|\n",
    "| `APP_NAME` | 应用名称 | HearSight ASR Backend |\n",
    "| `DEBUG` | 调试模式 | true |\n",
    "| `PORT` | 服务端口 | 8003 |\n",
    "\n",
    "## 运行模式选择\n",
    "\n",
    "通过 `ASR_MODE` 环境变量选择运行模式。\n",
    "\n",
    "`ASR_MODE=cloud` 为云端模式，轻量级部署，使用阿里云 DashScope API。\n",
    "\n",
    "`ASR_MODE=local` 为本地模式，离线运行，使用 FunASR 本地模型。\n",
    "\n",
    "[ASR_MODE 选择模式图](docs/mermaid图汇集/ASR_MODE选择模式图.md)\n",
    "\n",
    "```env\n",
    "ASR_MODE=cloud\n",
    "```\n",
    "\n",
    "##### 云端模式配置\n",
    "\n",
    "配置云端模式需要以下环境变量。\n",
    "\n",
    "**DashScope API Key**\n",
    "\n",
    "从阿里云控制台获取 API Key。访问 https://dashscope.console.aliyun.com/ 注册并获取。\n",
    "\n",
    "```env\n",
    "DASHSCOPE_API_KEY=sk-xxx\n",
    "```\n",
    "\n",
    "**DashScope 模型**\n",
    "\n",
    "默认使用 `paraformer-v2` 模型，这是推荐配置。\n",
    "\n",
    "```env\n",
    "DASHSCOPE_MODEL=paraformer-v2\n",
    "```\n",
    "\n",
    "**语言提示**\n",
    "\n",
    "指定支持的语言，用逗号分隔。支持中文（zh）和英文（en）。\n",
    "\n",
    "```env\n",
    "DASHSCOPE_LANGUAGE_HINTS=zh,en\n",
    "```\n",
    "\n",
    "**Supabase 配置（可选，用于文件上传）**\n",
    "\n",
    "若需要上传文件到云端存储，需要配置 Supabase。\n",
    "\n",
    "```env\n",
    "SUPABASE_URL=https://xxx.supabase.co\n",
    "SUPABASE_KEY=your-api-key\n",
    "SUPABASE_BUCKET_NAME=audio-storage\n",
    "SUPABASE_FOLDER_NAME=uploads\n",
    "SUPABASE_ADMIN_EMAIL=admin@example.com\n",
    "SUPABASE_ADMIN_PASSWORD=admin-password\n",
    "```\n",
    "\n",
    "##### 本地模式配置\n",
    "\n",
    "配置本地模式需要以下环境变量。\n",
    "\n",
    "**模型配置**\n",
    "\n",
    "配置使用的 FunASR 模型及其版本。\n",
    "\n",
    "```env\n",
    "LOCAL_MODEL_NAME=paraformer-zh\n",
    "LOCAL_MODEL_REVISION=v2.0.4\n",
    "```\n",
    "\n",
    "**VAD 模型**\n",
    "\n",
    "语音活动检测模型，用于自动分割音频中的有声段。\n",
    "\n",
    "```env\n",
    "LOCAL_VAD_MODEL=fsmn-vad\n",
    "LOCAL_VAD_MODEL_REVISION=v2.0.4\n",
    "```\n",
    "\n",
    "**标点模型**\n",
    "\n",
    "自动添加标点符号的模型。\n",
    "\n",
    "```env\n",
    "LOCAL_PUNC_MODEL=ct-punc-c\n",
    "LOCAL_PUNC_MODEL_REVISION=v2.0.4\n",
    "```\n",
    "\n",
    "**说话人模型**\n",
    "\n",
    "用于说话人识别的模型。\n",
    "\n",
    "```env\n",
    "LOCAL_SPK_MODEL=cam++\n",
    "```\n",
    "\n",
    "#### 配置验证\n",
    "\n",
    "启动应用前可以验证配置是否正确。\n",
    "\n",
    "```python\n",
    "from ASRBackend.config import settings\n",
    "\n",
    "# 检查基本配置\n",
    "print(f\"运行模式: {settings.asr_mode}\")\n",
    "print(f\"调试模式: {settings.debug}\")\n",
    "print(f\"服务端口: {settings.port}\")\n",
    "\n",
    "# 验证云端模式配置\n",
    "if settings.is_cloud_mode():\n",
    "    settings.validate_config()\n",
    "    print(\"云端模式配置有效\")\n",
    "```\n",
    "\n",
    "#### 常见配置场景\n",
    "\n",
    "##### 快速云端部署\n",
    "\n",
    "仅需配置 DashScope API Key。\n",
    "\n",
    "```env\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=sk-xxx\n",
    "```\n",
    "\n",
    "##### 本地离线运行\n",
    "\n",
    "仅需配置运行模式。\n",
    "\n",
    "```env\n",
    "ASR_MODE=local\n",
    "```\n",
    "\n",
    "##### 云端模式带文件上传\n",
    "\n",
    "需要配置 DashScope 和 Supabase。\n",
    "\n",
    "```env\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=sk-xxx\n",
    "SUPABASE_URL=https://xxx.supabase.co\n",
    "SUPABASE_KEY=your-api-key\n",
    "```\n",
    "\n",
    "#### Docker 环境配置\n",
    "\n",
    "使用 Docker 运行时，可通过环境变量覆盖配置。\n",
    "\n",
    "```bash\n",
    "docker run -p 8003:8003 \\\n",
    "  -e ASR_MODE=cloud \\\n",
    "  -e DASHSCOPE_API_KEY=sk-xxx \\\n",
    "  hearsight-asr:latest\n",
    "```\n",
    "\n",
    "或在 docker-compose.yml 中配置。\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  asr_backend:\n",
    "    image: hearsight-asr:latest\n",
    "    ports:\n",
    "      - \"8003:8003\"\n",
    "    environment:\n",
    "      ASR_MODE: cloud\n",
    "      DASHSCOPE_API_KEY: sk-xxx\n",
    "```\n",
    "\n",
    "#### 配置优先级\n",
    "\n",
    "配置覆盖优先级从高到低为：环境变量 > `.env` 文件 > 代码默认值。\n",
    "\n",
    "环境变量最高优先级，会覆盖所有其他配置。\n",
    "\n",
    "`.env` 文件用于本地开发配置，会覆盖代码中的默认值。\n",
    "\n",
    "代码中的默认值最低优先级。\n",
    "\n",
    "#### 故障排查\n",
    "\n",
    "若启动时出现配置错误，检查以下项。\n",
    "\n",
    "云端模式下，确认 `DASHSCOPE_API_KEY` 已正确设置且有效。\n",
    "\n",
    "若使用文件上传，确认 Supabase 相关配置完整正确。\n",
    "\n",
    "确认 `.env` 文件的编码为 UTF-8，否则中文字符可能显示异常。\n",
    "\n",
    "若环境变量未生效，确认变量名称正确（环境变量名不区分大小写）。\n",
    "\n",
    "有关启动和使用方面的更多信息，请参考 [ASR 快速开始文档](ASRBackend/docs/快速开始.md)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f4920",
   "metadata": {},
   "source": [
    "## HearSight 主后端快速开始\n",
    "\n",
    "### 获取源代码\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/li-xiu-qi/HearSight\n",
    "cd HearSight\n",
    "```\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "在 `backend/` 目录下创建 [.env](backend/.env) 文件，按需配置以下参数：\n",
    "\n",
    "```bash\n",
    "# PostgreSQL 数据库（必需）\n",
    "POSTGRES_USER=hearsight\n",
    "POSTGRES_PASSWORD=hearsight_pass\n",
    "POSTGRES_DB=hearsight\n",
    "POSTGRES_PORT=5432\n",
    "\n",
    "# 服务端口（可选）\n",
    "BACKEND_PORT=9999\n",
    "FRONTEND_PORT=10000\n",
    "\n",
    "# LLM 配置（必需，推荐使用百度AI Studio）\n",
    "LLM_PROVIDER=openai\n",
    "LLM_MODEL=ernie-4.5-300B-A47B\n",
    "LLM_PROVIDER_BASE_URL=https://aistudio.baidu.com/llm/lmapi/v3\n",
    "LLM_PROVIDER_API_KEY=your_ai_studio_api_key\n",
    "\n",
    "# Embedding 配置（必需）\n",
    "EMBEDDING_PROVIDER=openai\n",
    "EMBEDDING_PROVIDER_BASE_URL=https://api.siliconflow.cn/v1\n",
    "EMBEDDING_MODEL=BAAI/bge-m3\n",
    "EMBEDDING_PROVIDER_API_KEY=your_siliconflow_api_key\n",
    "\n",
    "# Bilibili（可选）\n",
    "BILIBILI_SESSDATA=your_sessdata_here\n",
    "\n",
    "# ASR Backend Service（可选，如果使用不同的 ASR 服务地址）\n",
    "ASR_BACKEND_URL=http://localhost:8003\n",
    "```\n",
    "\n",
    "在 `ASRBackend/` 目录下也需要创建 [.env](ASRBackend/.env) 文件：\n",
    "\n",
    "```bash\n",
    "# ASR 相关配置\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=your_dashscope_api_key\n",
    "```\n",
    "\n",
    "快速提示：项目推荐使用百度AI Studio的OpenAI兼容API作为LLM服务，可使用ernie-4.5-300B-A47B模型。配置AI_STUDIO_API_KEY（对应OpenAI SDK的api_key字段）和base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\"（对应OpenAI SDK的base_url字段）即可。更具体的内容可以参考：https://ai.baidu.com/ai-doc/AISTUDIO/rm344erns。Embedding服务默认使用硅基流动的OpenAI兼容API，平台地址：https://siliconflow.cn，免费额度申请：https://cloud.siliconflow.cn/i/FcjKykMn。DASHSCOPE_API_KEY 可从阿里云百炼获取。\n",
    "\n",
    "### 启动依赖服务\n",
    "\n",
    "HearSight 后端依赖以下服务：\n",
    "1. PostgreSQL 数据库\n",
    "2. Redis 服务器\n",
    "3. ASRBackend 服务（用于语音识别）\n",
    "\n",
    "可以通过 Docker 一键启动这些依赖服务：\n",
    "\n",
    "```bash\n",
    "# 在项目根目录（HearSight/）下执行\n",
    "docker-compose -f docker-compose.local.yml up -d postgres redis asr_backend\n",
    "```\n",
    "\n",
    "或者分别手动启动这些服务。\n",
    "\n",
    "更多关于 ASRBackend 的配置和使用信息，请参考 [ASRBackend 相关文档](ASRBackend/docs/)：\n",
    "- [ASR 服务设计文档](ASRBackend/docs/ASR_服务设计文档.md)\n",
    "- [ASR 快速开始指南](ASRBackend/docs/快速开始.md)\n",
    "- [ASR 快速配置](ASRBackend/docs/快速配置.md)\n",
    "- [ASR API 文档](ASRBackend/docs/api.md)\n",
    "- [ASR Docker 部署](ASRBackend/docs/docker_deployment.md)\n",
    "- [ASR 设计说明](ASRBackend/docs/设计说明.md)\n",
    "\n",
    "### 容器化部署（推荐）\n",
    "\n",
    "#### 使用项目根目录的 docker-compose 文件（推荐）\n",
    "\n",
    "一行命令启动后端服务及相关依赖：\n",
    "\n",
    "```bash\n",
    "# 在项目根目录（HearSight/）下执行\n",
    "docker-compose -f docker-compose.cloud.yml up -d --build\n",
    "```\n",
    "\n",
    "#### 使用 backend 目录下的 docker-compose 文件\n",
    "\n",
    "你也可以使用 backend 目录下专门为后端服务创建的统一 docker-compose 文件，但需要注意该文件不包含数据库和Redis服务，需要确保这些依赖服务已经运行：\n",
    "\n",
    "```bash\n",
    "# 在 backend/ 目录下执行，确保已启动 PostgreSQL、Redis 和 ASRBackend 服务\n",
    "docker-compose -f docker-compose.yml up -d --build\n",
    "```\n",
    "\n",
    "部署完成后，访问 http://localhost:9999 即可进入后端服务。\n",
    "\n",
    "如果仅需使用容器运行 PostgreSQL 数据库，而将后端在本地启动，请参考下方本地部署方案。\n",
    "\n",
    "### 本地开发部署\n",
    "\n",
    "#### 前置要求\n",
    "\n",
    "需要 PostgreSQL 数据库和 Redis 服务器运行。可通过 Docker 启动也可本地安装。\n",
    "\n",
    "#### 后端服务启动\n",
    "\n",
    "1. 安装依赖\n",
    "\n",
    "   ```bash\n",
    "   # 在项目根目录（HearSight/）下执行\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. 启动服务\n",
    "\n",
    "   ```bash\n",
    "   # 在项目根目录（HearSight/）下执行\n",
    "   python main.py\n",
    "   ```\n",
    "\n",
    "   后端运行在 `http://localhost:9999`\n",
    "\n",
    "### 验证服务\n",
    "\n",
    "打开浏览器访问 `http://localhost:9999/docs`，进入 Swagger 文档界面测试 API。\n",
    "\n",
    "或使用命令行测试：\n",
    "\n",
    "```bash\n",
    "curl http://localhost:9999/health\n",
    "```\n",
    "\n",
    "健康检查应该返回类似以下的信息表示启动成功：\n",
    "```json\n",
    "{\n",
    "  \"status\": \"healthy\",\n",
    "  \"timestamp\": \"2023-01-01T00:00:00\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 常见问题\n",
    "\n",
    "#### 数据库连接失败\n",
    "检查 [.env](backend/.env) 中的数据库配置是否正确，确保 PostgreSQL 服务正在运行。\n",
    "\n",
    "#### Redis 连接失败\n",
    "检查 Redis 配置，默认使用 `redis://localhost:6379/0`，确保 Redis 服务正在运行。\n",
    "\n",
    "#### 端口被占用\n",
    "修改启动命令中的端口号：\n",
    "```bash\n",
    "uvicorn main:app --host 0.0.0.0 --port 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ce3c8",
   "metadata": {},
   "source": [
    "## HearSight 前端快速开始\n",
    "\n",
    "### 环境准备\n",
    "\n",
    "#### 前置要求\n",
    "\n",
    "- Node.js 18.x 或更高版本\n",
    "- npm 或 yarn 包管理器\n",
    "\n",
    "#### 获取源代码\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/li-xiu-qi/HearSight\n",
    "cd HearSight/frontend\n",
    "```\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "在 `frontend/` 目录下创建 `.env` 文件，按需配置以下参数：\n",
    "\n",
    "```bash\n",
    "# 后端 API 地址（默认为本地开发环境）\n",
    "VITE_BACKEND_URL=http://localhost:9999\n",
    "\n",
    "# 是否在 Docker 环境中运行（默认为false）\n",
    "VITE_USE_DOCKER=false\n",
    "\n",
    "# 后端主机地址（用于Docker环境）\n",
    "BACKEND_HOST=localhost\n",
    "\n",
    "# 后端端口（用于Docker环境）\n",
    "BACKEND_PORT=9999\n",
    "\n",
    "# 是否使用Docker（用于Vite代理配置）\n",
    "USE_DOCKER=false\n",
    "```\n",
    "\n",
    "环境变量说明：\n",
    "\n",
    "- `VITE_BACKEND_URL`: 前端应用连接的后端API地址\n",
    "- `VITE_USE_DOCKER`: 标识是否在Docker环境中运行\n",
    "- `BACKEND_HOST` 和 `BACKEND_PORT`: 用于Vite代理配置，在Docker环境中指向后端服务容器\n",
    "- `USE_DOCKER`: 控制Vite代理使用容器名还是localhost\n",
    "\n",
    "### 安装依赖\n",
    "\n",
    "```bash\n",
    "npm install\n",
    "```\n",
    "\n",
    "### 容器化部署（推荐）\n",
    "\n",
    "#### 使用项目根目录的 Docker Compose（推荐）\n",
    "\n",
    "项目根目录提供了完整的 [docker-compose.cloud.yml](docker-compose.cloud.yml) 文件，可以一键启动包括前端在内的所有服务：\n",
    "\n",
    "```bash\n",
    "# 在项目根目录执行\n",
    "docker-compose -f ../docker-compose.cloud.yml up -d --build\n",
    "```\n",
    "\n",
    "#### 使用前端独立的 Docker Compose\n",
    "\n",
    "前端目录下提供了独立的 [docker-compose.yml](frontend/docker-compose.yml) 文件，可用于单独部署前端服务：\n",
    "\n",
    "```bash\n",
    "# 在 frontend 目录下执行\n",
    "docker-compose up -d --build\n",
    "```\n",
    "\n",
    "注意：使用独立的 docker-compose 文件时，需要确保后端服务已经在运行并且可以通过网络访问。\n",
    "\n",
    "#### 单独构建前端镜像\n",
    "\n",
    "```bash\n",
    "# 构建 Docker 镜像\n",
    "docker build -t hearsight-frontend .\n",
    "\n",
    "# 运行容器\n",
    "docker run -p 5173:5173 hearsight-frontend\n",
    "```\n",
    "\n",
    "### 本地开发部署\n",
    "\n",
    "#### 启动开发服务器\n",
    "\n",
    "```bash\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "默认情况下，开发服务器将在 `http://localhost:5173` 上运行。\n",
    "\n",
    "#### 构建生产版本\n",
    "\n",
    "```bash\n",
    "npm run build\n",
    "```\n",
    "\n",
    "构建后的文件将位于 `dist` 目录中。\n",
    "\n",
    "#### 预览生产构建\n",
    "\n",
    "```bash\n",
    "npm run preview\n",
    "```\n",
    "\n",
    "### 测试\n",
    "\n",
    "运行测试：\n",
    "\n",
    "```bash\n",
    "npm run test\n",
    "```\n",
    "\n",
    "### 常见问题\n",
    "\n",
    "#### API 连接失败\n",
    "\n",
    "检查 `.env` 文件中的 `VITE_BACKEND_URL` 配置是否正确，确保后端服务正在运行。\n",
    "\n",
    "#### 依赖安装失败\n",
    "\n",
    "尝试清除缓存后重新安装：\n",
    "\n",
    "```bash\n",
    "npm cache clean --force\n",
    "rm -rf node_modules package-lock.json\n",
    "npm install\n",
    "```\n",
    "\n",
    "#### 端口被占用\n",
    "\n",
    "修改 `vite.config.ts` 中的端口配置：\n",
    "\n",
    "```javascript\n",
    "export default defineConfig({\n",
    "  server: {\n",
    "    port: 5173 // 修改为其他端口\n",
    "  }\n",
    "})\n",
    "```\n",
    "\n",
    "#### Docker 环境中无法连接后端\n",
    "\n",
    "确保在 Docker 环境中正确设置了 `USE_DOCKER=true` 和 `BACKEND_HOST=backend` 环境变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b39c33",
   "metadata": {},
   "source": [
    "## 功能详解\n",
    "\n",
    "![功能结构说明图](https://oss-liuchengtu.hudunsoft.com/userimg/3b/3b446977cb5b2dd11fe3815966a8e839.png)\n",
    "\n",
    "### 1. 多源媒体导入\n",
    "\n",
    "集成哔哩哔哩接口可直接获取视频（含登录内容），同时支持本地上传多种格式的音视频文件。系统自动处理文件管理和元数据存储，用户无需手动处理繁琐的文件操作。\n",
    "\n",
    "![多源媒体导入系统](https://oss-liuchengtu.hudunsoft.com/userimg/a4/a48dd834a2ec5e8436aa8ce02b697e09.png)\n",
    "\n",
    "### 2. 精准语音识别与时间戳分句\n",
    "\n",
    "![实时语音转文字流程](https://oss-liuchengtu.hudunsoft.com/userimg/8c/8c50fbd2590e589172e32f260dfd8aab.png)\n",
    "\n",
    "采用行业前沿的 ASR 模型，支持热词识别优化垂直领域准确度。系统自动按句义分割，每个分句精确对应音频时间戳，支持点击即跳转到音视频位置，打破传统文案的线性查看方式。\n",
    "\n",
    "![双模式 ASR 架构，便于边缘化部署](https://oss-liuchengtu.hudunsoft.com/userimg/c3/c3b18238ab2fb36846e80aff302b12b7.png)\n",
    "\n",
    "### 3. 分层级摘要生成与版本管理\n",
    "\n",
    "集成大语言模型生成分层级摘要，既能快速获取段落关键信息，也能完整掌握全文内容脉络。摘要自动入库，支持查看历史版本与迭代对比，支持强制重新生成自动覆盖，让内容分析全过程可追溯。\n",
    "\n",
    "### 4. 多语言翻译与存储\n",
    "\n",
    "支持一键翻译为多种目标语言，后台异步处理不阻塞主流程，支持实时查看翻译进度。翻译结果完整持久化，多语言内容共存于一个项目中，轻松管理国际化内容。\n",
    "\n",
    "![上下文感知的多语言翻译服务架构设计](https://oss-liuchengtu.hudunsoft.com/userimg/1f/1f311c4fc7fac0ed15a4f0ca3b9e3a07.png)\n",
    "\n",
    "### 5. 深度问答交互\n",
    "\n",
    "基于原始转写内容进行上下文感知的问答。支持多轮追问与对话历史完整保留，系统能准确把握内容脉络，给出针对性的分析答案。\n",
    "\n",
    "### 6. 图文融合呈现\n",
    "\n",
    "自动关联视频关键帧到摘要和问答结果中（仅适用于视频内容）。用户可点击查看大图，实现图文结合的直观表达，让复杂概念更容易理解。\n",
    "\n",
    "## 适用场景\n",
    "\n",
    "学术研究：快速整理讲座音频或视频，建立参考文献档案库。教育培训：自动生成教学讲义和习题解析。内容创作：批量处理视频脚本和文案素材。企业培训：构建结构化的内部知识库与学习平台。客户服务：分析客服录音提取关键问题与解决方案。市场研究：监测竞品视频内容并自动生成分析报告。\n",
    "\n",
    "## 项目结构\n",
    "\n",
    "详细的项目结构说明请参考 [项目结构](docs/项目结构.md)。\n",
    "\n",
    "## API 文档\n",
    "\n",
    "API 接口文档请参考 [API 文档导航](docs/api_文档导航.md)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa5d9d",
   "metadata": {},
   "source": [
    "## 项目结构详细说明\n",
    "\n",
    "HearSight 采用现代化的微服务架构设计。后端基于 FastAPI 构建高性能 RESTful API，通过 PostgreSQL 实现数据的持久化和查询优化；前端采用 React 18 + TypeScript + Tailwind CSS 提供交互流畅的用户界面。整体支持 Docker 容器化部署，开箱即用。\n",
    "\n",
    "![架构图](https://oss-liuchengtu.hudunsoft.com/userimg/b5/b54f2ca20885a98aa90ec0557b8354e1.png)\n",
    "\n",
    "### 项目目录结构\n",
    "\n",
    "```text\n",
    "HearSight/\n",
    "├── ASRBackend/                # 语音识别后端服务\n",
    "│   ├── asr_functions/         # ASR功能实现\n",
    "│   ├── routers/               # API路由层\n",
    "│   ├── services/              # 业务服务层\n",
    "│   ├── supabase_utils/        # Supabase工具\n",
    "│   ├── tests/                 # 测试文件\n",
    "│   ├── docs/                  # 文档\n",
    "│   ├── example_tests/         # 示例测试\n",
    "│   ├── config.py              # 配置管理\n",
    "│   ├── main.py                # 启动入口\n",
    "│   ├── Dockerfile.local       # 本地模式Docker配置\n",
    "│   ├── Dockerfile.cloud       # 云端模式Docker配置\n",
    "│   ├── docker-compose.local.yml  # 本地模式编排配置\n",
    "│   ├── docker-compose.cloud.yml  # 云端模式编排配置\n",
    "│   ├── requirements-local.txt    # 本地模式依赖\n",
    "│   └── requirements-cloud.txt    # 云端模式依赖\n",
    "│\n",
    "├── backend/                   # 主后端服务\n",
    "│   ├── routers/               # API 路由层\n",
    "│   │   ├── chat/              # 聊天相关接口\n",
    "│   │   ├── asr_router.py      # 语音识别相关接口\n",
    "│   │   ├── download_router.py # 媒体下载接口\n",
    "│   │   ├── progress_router.py # 进度查询接口\n",
    "│   │   ├── thumbnail_router.py# 缩略图接口\n",
    "│   │   ├── transcript_router.py # 媒体管理接口\n",
    "│   │   ├── translate_router.py # 翻译接口\n",
    "│   │   ├── upload_router.py   # 文件上传接口\n",
    "│   │   └── ...                # 其他功能路由\n",
    "│   ├── services/              # 业务服务层\n",
    "│   │   ├── chat_service.py        # 聊天服务\n",
    "│   │   ├── download_service.py    # 下载服务\n",
    "│   │   ├── translate_service.py   # 翻译服务\n",
    "│   │   ├── transcript_service.py  # 转写服务\n",
    "│   │   └── ...                    # 其他服务\n",
    "│   ├── db/                    # 数据库访问层\n",
    "│   │   ├── chat_message_crud.py   # 聊天消息数据操作\n",
    "│   │   ├── chat_session_crud.py   # 聊天会话数据操作\n",
    "│   │   ├── job_base_store.py      # 任务基础数据操作\n",
    "│   │   ├── job_result_store.py    # 任务结果数据操作\n",
    "│   │   ├── job_status_store.py    # 任务状态数据操作\n",
    "│   │   ├── transcript_base_crud.py# 转写基础数据操作\n",
    "│   │   ├── transcript_crud.py     # 转写数据操作\n",
    "│   │   ├── transcript_summary_crud.py  # 转写摘要数据操作\n",
    "│   │   ├── transcript_translation_crud.py  # 转写翻译数据操作\n",
    "│   │   └── ...\n",
    "│   ├── audio2text/            # 语音识别模块\n",
    "│   │   └── asr_sentence_segments.py # ASR 与分句处理\n",
    "│   ├── media_processing/      # 媒体处理模块\n",
    "│   │   ├── audio/             # 音频处理\n",
    "│   │   ├── video/             # 视频处理\n",
    "│   │   ├── downloader_factory.py  # 下载器工厂\n",
    "│   │   └── upload_handler.py      # 上传处理\n",
    "│   ├── queues/                # 队列任务处理\n",
    "│   │   ├── tasks/             # 具体任务实现\n",
    "│   │   └── worker_launcher.py # 工作进程启动器\n",
    "│   ├── text_process/          # 文本处理模块\n",
    "│   │   ├── translate/         # 翻译处理\n",
    "│   │   ├── summarize.py       # 摘要生成\n",
    "│   │   ├── translate.py       # 翻译实现\n",
    "│   │   └── ...\n",
    "│   ├── utils/                 # 工具函数\n",
    "│   ├── config.py              # 配置管理\n",
    "│   ├── main.py                # 启动入口\n",
    "│   ├── app.py                 # FastAPI 应用工厂\n",
    "│   ├── Dockerfile             # Docker配置\n",
    "│   ├── requirements.txt       # Python依赖\n",
    "│   └── ...\n",
    "│\n",
    "├── frontend/                  # 前端应用（React 18 + TypeScript）\n",
    "│   ├── src/\n",
    "│   │   ├── components/        # React 组件库\n",
    "│   │   │   ├── RightPanel/    # 右侧功能面板\n",
    "│   │   │   ├── VideoPlayer/   # 视频播放器\n",
    "│   │   │   └── ...\n",
    "│   │   ├── features/app/      # 应用主体功能\n",
    "│   │   ├── services/          # API 服务层\n",
    "│   │   ├── types/             # TypeScript 类型定义\n",
    "│   │   ├── hooks/             # 自定义 React hooks\n",
    "│   │   ├── HomePage/          # 首页\n",
    "│   │   └── App.tsx            # 应用入口\n",
    "│   ├── vite.config.ts         # Vite 构建配置\n",
    "│   └── tailwind.config.js     # Tailwind CSS 配置\n",
    "│\n",
    "├── docker-compose.cloud.yml   # 云端部署容器编排配置\n",
    "├── docker-compose.local.yml   # 本地开发容器编排配置\n",
    "├── docker-compose.cloud.linux.yml   # Linux云端部署容器编排配置\n",
    "├── docker-compose.cloud.arm.linux.yml  # ARM Linux云端部署容器编排配置\n",
    "├── README.md                  # 项目说明\n",
    "└── docs/                      # 项目文档\n",
    "    ├── 快速开始.md            # 快速开始指南\n",
    "    ├── 项目结构.md            # 项目结构说明\n",
    "    └── ...                    # 其他文档\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6212dca",
   "metadata": {},
   "source": [
    "## Radxa设备大语言模型部署指南\n",
    "\n",
    "### 概述\n",
    "\n",
    "本文档介绍在Radxa设备上部署大型语言模型（LLM）的工具和方法，主要包括Llama.cpp和Ollama。\n",
    "\n",
    "### Llama.cpp\n",
    "\n",
    "Llama.cpp的主要目标是在各种硬件（本地和云端）上实现LLM推理，只需最少的设置，同时提供最先进的性能。\n",
    "\n",
    "#### 量化格式对比\n",
    "\n",
    "以下是不同的量化格式及其性能表现（基于Llama-3-8B模型）：\n",
    "\n",
    "```text\n",
    "2 或 Q4_0    : 4.34GB, +0.4685 困惑度 @ Llama-3-8B\n",
    "3 或 Q4_1    : 4.78GB, +0.4511 困惑度 @ Llama-3-8B\n",
    "8 或 Q5_0    : 5.21GB, +0.1316 困惑度 @ Llama-3-8B\n",
    "9 或 Q5_1    : 5.65GB, +0.1062 困惑度 @ Llama-3-8B\n",
    "19 或 IQ2_XXS : 2.06 bpw 量化\n",
    "20 或 IQ2_XS  : 2.31 bpw 量化\n",
    "28 或 IQ2_S   : 2.5  bpw 量化\n",
    "29 或 IQ2_M   : 2.7  bpw 量化\n",
    "24 或 IQ1_S   : 1.56 bpw 量化\n",
    "31 或 IQ1_M   : 1.75 bpw 量化\n",
    "36 或 TQ1_0   : 1.69 bpw 三值化\n",
    "37 或 TQ2_0   : 2.06 bpw 三值化\n",
    "10 或 Q2_K    : 2.96GB, +3.5199 困惑度 @ Llama-3-8B\n",
    "21 或 Q2_K_S  : 2.96GB, +3.1836 困惑度 @ Llama-3-8B\n",
    "23 或 IQ3_XXS : 3.06 bpw 量化\n",
    "26 或 IQ3_S   : 3.44 bpw 量化\n",
    "27 或 IQ3_M   : 3.66 bpw 量化混合\n",
    "12 或 Q3_K    : Q3_K_M的别名\n",
    "22 或 IQ3_XS  : 3.3 bpw 量化\n",
    "11 或 Q3_K_S  : 3.41GB, +1.6321 困惑度 @ Llama-3-8B\n",
    "12 或 Q3_K_M  : 3.74GB, +0.6569 困惑度 @ Llama-3-8B\n",
    "13 或 Q3_K_L  : 4.03GB, +0.5562 困惑度 @ Llama-3-8B\n",
    "25 或 IQ4_NL  : 4.50 bpw 非线性量化\n",
    "30 或 IQ4_XS  : 4.25 bpw 非线性量化\n",
    "15 或 Q4_K    : Q4_K_M的别名\n",
    "14 或 Q4_K_S  : 4.37GB, +0.2689 困惑度 @ Llama-3-8B\n",
    "15 或 Q4_K_M  : 4.58GB, +0.1754 困惑度 @ Llama-3-8B\n",
    "17 或 Q5_K    : Q5_K_M的别名\n",
    "16 或 Q5_K_S  : 5.21GB, +0.1049 困惑度 @ Llama-3-8B\n",
    "17 或 Q5_K_M  : 5.33GB, +0.0569 困惑度 @ Llama-3-8B\n",
    "18 或 Q6_K    : 6.14GB, +0.0217 困惑度 @ Llama-3-8B\n",
    "7 或 Q8_0    : 7.96GB, +0.0026 困惑度 @ Llama-3-8B\n",
    "1 或 F16     : 14.00GB, +0.0020 困惑度 @ Mistral-7B\n",
    "32 或 BF16    : 14.00GB, -0.0050 困惑度 @ Mistral-7B\n",
    "0 或 F32     : 26.00GB @ 7B\n",
    "        COPY    : 仅复制张量，不量化\n",
    "```\n",
    "\n",
    "#### 实际使用示例\n",
    "\n",
    "##### 对话示例\n",
    "\n",
    "```text\n",
    "> 你好，你是谁\n",
    "<think>\n",
    "\n",
    "</think>\n",
    "\n",
    "你好！我是DeepSeek-R1，由DeepSeek创建的人工智能助手。我随时为您服务，很乐意协助您解决任何疑问或任务。\n",
    "```\n",
    "\n",
    "##### 性能基准测试\n",
    "\n",
    "在Radxa Orion O6上进行性能测试：\n",
    "\n",
    "```bash\n",
    "radxa@orion-o6:~/llama.cpp/build/bin$ ./llama-bench -m ~/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf -t 8\n",
    "| 模型                          |       大小 |     参数量 | 后端    | 线程数 |          测试 |                  速度 |\n",
    "| ------------------------------ | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n",
    "| qwen2 1.5B Q4_K - Medium       |   1.04 GB |     1.78 B | CPU        |       8 |         pp512 |         64.60 ± 0.27 |\n",
    "| qwen2 1.5B Q4_K - Medium       |   1.04 GB |     1.78 B | CPU        |       8 |         tg128 |         36.29 ± 0.16 |\n",
    "```\n",
    "\n",
    "测试结果显示，在8线程配置下，预填充速度达到64.60 tokens/秒，生成速度达到36.29 tokens/秒。\n",
    "\n",
    "### Ollama\n",
    "\n",
    "Ollama是一个在本地运行和管理大型语言模型（LLM）的工具。它使您能够轻松地在本地设备上拉取、运行和管理各种AI模型（如LLaMA、Mistral和Gemma），而无需复杂的环境配置。\n",
    "\n",
    "#### 安装Ollama\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "关于本地构建方法，请参考[官方文档](https://github.com/ollama/ollama/blob/main/docs/development.md)。\n",
    "\n",
    "#### 使用方法\n",
    "\n",
    "##### 拉取模型\n",
    "\n",
    "此命令从互联网下载模型文件。\n",
    "\n",
    "```bash\n",
    "ollama pull deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "##### 运行模型\n",
    "\n",
    "此命令直接运行模型。如果模型未在本地缓存，它会在运行前自动下载。\n",
    "\n",
    "```bash\n",
    "ollama run deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "##### 显示模型信息\n",
    "\n",
    "```bash\n",
    "ollama show deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "##### 列出计算机上的模型\n",
    "\n",
    "```bash\n",
    "ollama list\n",
    "```\n",
    "\n",
    "##### 列出当前已加载的模型\n",
    "\n",
    "```bash\n",
    "ollama ps\n",
    "```\n",
    "\n",
    "##### 停止当前正在运行的模型\n",
    "\n",
    "```bash\n",
    "ollama stop deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "##### 删除模型\n",
    "\n",
    "```bash\n",
    "ollama rm deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "### 参考\n",
    "\n",
    "- Llama.cpp官方文档：<https://github.com/ggml-org/llama.cpp>\n",
    "- 使用Llama.cpp在Radxa上运行LLM：<https://docs.radxa.com/en/orion/o6/app-development/artificial-intelligence/llama_cpp>\n",
    "- Ollama官方文档：<https://github.com/ollama/ollama>\n",
    "- 使用Ollama在Radxa上运行LLM：<https://docs.radxa.com/en/orion/o6/app-development/artificial-intelligence/ollama>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee5d92",
   "metadata": {},
   "source": [
    "## ARM设备Docker构建指南\n",
    "\n",
    "### 概述\n",
    "\n",
    "本指南介绍如何将HearSight项目的Docker镜像构建并部署到ARM架构设备上。如ARM设备资源充足，推荐直接在ARM设备上构建；否则，使用交叉构建方式。\n",
    "\n",
    "### 构建流程\n",
    "\n",
    "#### 直接构建流程（推荐）\n",
    "\n",
    "[ARM设备直接构建流程图](docs/mermaid图汇集/ARM设备直接构建流程图.md)\n",
    "\n",
    "#### 交叉构建流程（备选）\n",
    "\n",
    "[ARM设备交叉构建流程图](docs/mermaid图汇集/ARM设备交叉构建流程图.md)\n",
    "\n",
    "### 选择合适的docker-compose文件\n",
    "\n",
    "HearSight项目提供多个docker-compose文件，根据运行环境选择：\n",
    "\n",
    "- **docker-compose.cloud.yml**：适用于Windows主机，使用build指令构建镜像，云端ASR模式。\n",
    "- **docker-compose.cloud.linux.yml**：适用于Linux主机，使用build指令构建镜像，云端ASR模式。\n",
    "- **docker-compose.cloud.arm.linux.yml**：适用于ARM Linux设备，使用预构建的image指令，云端ASR模式。\n",
    "- **docker-compose.local.yml**：适用于Linux主机，使用build指令构建镜像，本地ASR模式（需要CUDA支持）。\n",
    "\n",
    "根据主机操作系统和ASR模式选择相应文件：\n",
    "\n",
    "- Windows（云端ASR）：使用docker-compose.cloud.yml\n",
    "- Linux（云端ASR）：使用docker-compose.cloud.linux.yml\n",
    "- ARM Linux（云端ASR）：使用docker-compose.cloud.arm.linux.yml\n",
    "- Linux（本地ASR）：使用docker-compose.local.yml\n",
    "\n",
    "**重要说明**：对于ARM设备，推荐优先使用云端模式的docker-compose文件（如docker-compose.cloud.arm.linux.yml），因为本地的语音识别docker需要依赖CUDA，而ARM设备上CUDA支持有限或配置复杂。云端模式使用阿里云DashScope API，无需本地GPU资源。\n",
    "\n",
    "### 配置环境变量\n",
    "\n",
    "运行docker-compose前，创建环境变量文件：\n",
    "\n",
    "- **backend/.env**：后端服务配置，包含数据库、API密钥等。\n",
    "- **ASRBackend/.env**：ASR后端配置，包含API密钥等。\n",
    "\n",
    "参考项目中的.env.example文件。\n",
    "\n",
    "#### 获取API密钥\n",
    "\n",
    "- **语音识别模型密钥 (DASHSCOPE_API_KEY)**：前往阿里云百炼控制台获取DashScope API密钥。\n",
    "- **Supabase配置**：前往 [Supabase官网](https://supabase.com/) 注册并创建项目。选择Public bucket，配置策略为：允许用户上传文件到名为asr的存储桶，文件名以.wav结尾，用户为<lixiuqixiaoke@qq.com>。\n",
    "\n",
    "示例backend/.env内容：\n",
    "\n",
    "```\n",
    "POSTGRES_USER=hearsight\n",
    "POSTGRES_PASSWORD=hearsight_pass\n",
    "POSTGRES_DB=hearsight\n",
    "BACKEND_PORT=9999\n",
    "FRONTEND_PORT=10000\n",
    "OPENAI_API_KEY=your_key\n",
    "# 其他变量...\n",
    "```\n",
    "\n",
    "示例ASRBackend/.env内容：\n",
    "\n",
    "```\n",
    "ASR_MODE=cloud\n",
    "DASHSCOPE_API_KEY=your_key\n",
    "SUPABASE_URL=https://your-project.supabase.co\n",
    "SUPABASE_KEY=your-anon-key-here\n",
    "SUPABASE_BUCKET_NAME=test-public\n",
    "SUPABASE_FOLDER_NAME=asr\n",
    "SUPABASE_ADMIN_EMAIL=your-admin-email@example.com\n",
    "SUPABASE_ADMIN_PASSWORD=your-admin-password\n",
    "```\n",
    "\n",
    "确保.env文件不提交到版本控制。\n",
    "\n",
    "### 直接在ARM设备上构建\n",
    "\n",
    "如果ARM设备资源充足，直接在ARM设备上构建镜像。\n",
    "\n",
    "#### 步骤\n",
    "\n",
    "1. 在ARM设备上安装Docker。\n",
    "2. 配置Docker镜像加速。\n",
    "3. 传输项目代码到ARM设备：\n",
    "\n",
    "   ```\n",
    "   scp -r C:\\Users\\ke\\Downloads\\HearSight root@arm-ip:/home/ke123/\n",
    "   ```\n",
    "\n",
    "   或使用U盘传输。\n",
    "\n",
    "4. 创建环境变量文件。\n",
    "5. 构建并运行：\n",
    "\n",
    "   ```\n",
    "   cd /home/ke123/HearSight\n",
    "   docker-compose -f docker-compose.cloud.linux.yml build\n",
    "   docker-compose -f docker-compose.cloud.linux.yml up -d\n",
    "   ```\n",
    "\n",
    "#### 优势\n",
    "\n",
    "- 无需x86主机。\n",
    "- 无需传输大文件。\n",
    "- 确保兼容性。\n",
    "\n",
    "#### 注意\n",
    "\n",
    "- ARM设备需足够资源。\n",
    "- 构建时间较长。\n",
    "- 网络慢时配置加速。\n",
    "\n",
    "### 交叉构建到ARM设备\n",
    "\n",
    "如果ARM设备资源有限，在x86主机上交叉构建ARM64镜像，然后传输。\n",
    "\n",
    "#### 详细步骤\n",
    "\n",
    "1. 启用Docker Buildx：\n",
    "\n",
    "   ```\n",
    "   docker buildx create --use\n",
    "   ```\n",
    "\n",
    "2. 检查Dockerfile兼容性，确保基础镜像支持ARM64。\n",
    "3. 构建多架构镜像：\n",
    "\n",
    "   ```\n",
    "   docker buildx build --platform linux/arm64 -t image:arm64 --load ./backend\n",
    "   ```\n",
    "\n",
    "4. 保存镜像为文件：\n",
    "\n",
    "   ```\n",
    "   mkdir -p docker-images\n",
    "   docker save hearsight-backend:arm64 > docker-images/backend-arm64.tar\n",
    "   docker save hearsight-frontend:arm64 > docker-images/frontend-arm64.tar\n",
    "   docker save hearsight-asr-backend:arm64 > docker-images/asr-backend-arm64.tar\n",
    "   docker save hearsight-celery-worker:arm64 > docker-images/celery-worker-arm64.tar\n",
    "   ```\n",
    "\n",
    "5. 传输到ARM设备：\n",
    "\n",
    "   ```\n",
    "   scp docker-images/*.tar user@arm-ip:/path/\n",
    "   ```\n",
    "\n",
    "   或使用U盘。\n",
    "\n",
    "6. 在ARM设备上加载并运行：\n",
    "\n",
    "   - 加载镜像：\n",
    "\n",
    "     ```\n",
    "     docker load < backend-arm64.tar\n",
    "     docker load < frontend-arm64.tar\n",
    "     docker load < asr-backend-arm64.tar\n",
    "     docker load < celery-worker-arm64.tar\n",
    "     ```\n",
    "\n",
    "   - 运行服务：\n",
    "\n",
    "     ```\n",
    "     docker-compose -f docker-compose.cloud.yml up -d\n",
    "     ```\n",
    "\n",
    "     或单独运行celery-worker：\n",
    "\n",
    "     ```\n",
    "     docker run -d --name celery-worker hearsight-celery-worker:arm64 python -m backend.queues.worker_launcher\n",
    "     ```\n",
    "\n",
    "#### 构建多个服务\n",
    "\n",
    "需要构建的服务：\n",
    "\n",
    "- backend：\n",
    "\n",
    "  ```\n",
    "  docker buildx build --platform linux/arm64 -t hearsight-backend:arm64 --load -f backend/Dockerfile .\n",
    "  ```\n",
    "\n",
    "- frontend：\n",
    "\n",
    "  ```\n",
    "  docker buildx build --platform linux/arm64 -t hearsight-frontend:arm64 --load ./frontend\n",
    "  ```\n",
    "\n",
    "- asr-backend：\n",
    "\n",
    "  ```\n",
    "  docker buildx build --platform linux/arm64 -t hearsight-asr-backend:arm64 --load -f Dockerfile.cloud .\n",
    "  ```\n",
    "\n",
    "- celery-worker：\n",
    "\n",
    "  ```\n",
    "  docker buildx build --platform linux/arm64 -t hearsight-celery-worker:arm64 --load -f backend/Dockerfile .\n",
    "  ```\n",
    "\n",
    "- redis：使用现成镜像，无需构建。\n",
    "\n",
    "### 在ARM设备上安装Docker\n",
    "\n",
    "如果ARM设备未安装Docker，按以下步骤安装：\n",
    "\n",
    "```\n",
    "# 更新包索引\n",
    "sudo apt update\n",
    "\n",
    "# 安装必要包\n",
    "sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release\n",
    "\n",
    "# 添加Docker GPG密钥\n",
    "curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n",
    "\n",
    "# 添加Docker仓库\n",
    "echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "# 更新包索引\n",
    "sudo apt update\n",
    "\n",
    "# 安装Docker CE\n",
    "sudo apt install docker-ce docker-ce-cli containerd.io\n",
    "\n",
    "# 启动Docker服务\n",
    "sudo systemctl start docker\n",
    "\n",
    "# 设置开机自启\n",
    "sudo systemctl enable docker\n",
    "\n",
    "# 安装Docker Compose\n",
    "sudo apt install docker-compose\n",
    "\n",
    "# 添加用户到docker组\n",
    "sudo usermod -aG docker $USER\n",
    "```\n",
    "\n",
    "安装后，验证版本。\n",
    "\n",
    "#### 配置Docker镜像加速\n",
    "\n",
    "配置镜像加速源，如<https://docker.1ms.run：>\n",
    "\n",
    "- 全局配置：\n",
    "\n",
    "  编辑 /etc/docker/daemon.json：\n",
    "\n",
    "  ```\n",
    "  {\n",
    "    \"registry-mirrors\": [\"https://docker.1ms.run\"]\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  重启Docker：\n",
    "\n",
    "  ```\n",
    "  sudo systemctl restart docker\n",
    "  ```\n",
    "\n",
    "- 针对特定镜像：在docker-compose中修改image。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 确保Docker版本支持Buildx。\n",
    "- 调整Dockerfile为ARM兼容。\n",
    "- 构建时间长，建议在x86上进行。\n",
    "- 测试ARM设备运行效果。\n",
    "- 如果PyPI下载SSL错误，更换PIP_INDEX_URL为其他源，并添加PIP_TRUSTED_HOST。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e502dd",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本教程详细介绍了HearSight项目的安装、配置和使用方法。HearSight是一个强大的音视频内容智能分析工具，能够帮助用户快速处理和分析多媒体内容。\n",
    "\n",
    "通过本教程，你可以学习到：\n",
    "\n",
    "- 如何获取和配置HearSight项目\n",
    "- 不同组件（后端、ASR、前端）的启动方法\n",
    "- 项目的核心功能和适用场景\n",
    "- 常见问题的解决方法\n",
    "\n",
    "如果在部署或使用过程中遇到问题，可以参考各个组件的文档或寻求社区帮助。\n",
    "\n",
    "祝你使用愉快！"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
